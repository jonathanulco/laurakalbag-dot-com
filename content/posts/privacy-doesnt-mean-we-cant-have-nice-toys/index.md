---
title: "Privacy doesn’t mean we can’t have nice toys"
date: 2019-03-21T09:27:10Z
draft: true
tags: ["privacy", "social justice", "“innovation”"]
categories: ["Privacy"]
type: "post"
body_classes: "blog"
colours:
    primary-bg: "3,100%,92%" # hsl(3,100%,92%)
    secondary-bg: "5,100%,89%" # hsl(5,100%,89%)
    text: "195,100%,20%" # hsl(195,100%,20%)
    linktext: "195,100%,25%" # hsl(195,100%,25%)
    darklinktext: "195,70%,14%" # hsl(195,70%,14%)
    brilliant: "196,100%,42%" # hsl(196,100%,42%)
    tab-two: "278,9%,83%" # hsl(278,9%,83%)
    tab-three: "205,35%,76%" # hsl(205,35%,76%)
    tab-four: "199,52%,67%" # hsl(199,52%,67%)
    tab-five: "197,62%,59%" # hsl(197,62%,59%)
    tab-six: "196,68%,51%" # hsl(196,68%,51%)
---

“[Actually, I want to hand over even more of my personal data to big tech](https://www.fastcompany.com/90315789/actually-i-want-to-hand-over-even-more-of-my-data-to-big-tech).” This article popping up in my RSS feed this morning has irritated me immensely. Not least because two other articles in the series, [Trading privacy for survival is another tax on the poor](https://www.fastcompany.com/90317495/another-tax-on-the-poor-surrendering-privacy-for-survival) and [How the tragic death of Do Not Track ruined the web for everyone](https://www.fastcompany.com/90308068/how-the-tragic-death-of-do-not-track-ruined-the-web-for-everyone), were so insightful. It’s a weak statement that presents a dichotomy where none exists. It knows it’s being contrarian, and the intentions behind statements like this should concern us.<!--more-->

Privacy and innovation are not in opposition.

Privacy in technology is our right as individuals to choose what we want to share, and what we want to keep to ourselves. It is our right to not have personal data about us shared without our consent, and for it to be used against us. And our data is often used against us, as that article I mentioned before, [Trading privacy for survival is another tax on the poor](https://www.fastcompany.com/90317495/another-tax-on-the-poor-surrendering-privacy-for-survival), explains so well.

I hate using the term *innovation* because it has been co-opted by men in suits who make elaborate pitches for fairy dust technologies they barely understand. Innovation is simply new technology, using ideas and processes that do not already exist. Innovation in technology does not necessarily require invasion of our privacy, the exploitation of our personal data, or everything in the world being connected in a massive dystopian data hive.

My concern is that articles implying that handing over our personal data is necessary to innovation are just repeating the same messages that big tech corporations, and their investors, want us to believe. They want us to accept that surveillance capitalism, the practice of extracting our personal data and using it for financial gain, is the only way technology can thrive, and the only way we can get the toys we want. Sure, it is the prevailing model. As Shoshana Zuboff says in the Age of Surveillance Capitalism, “[Surveillance Capitalism’s] mechanisms and economic imperatives have become the default model for most internet-based businesses.” But surveillance capitalism is not the only way, and it is certainly not for our benefit.

> “Surveillance capitalism operates through unprecedented asymmetries in knowledge and the power that accrues to knowledge. Surveillance capitalists know everything *about us*, whereas their operations are designed to be unknowable *to us*. They accumulate vast domains of new knowledge *from us*, but not *for us*. They predict our futures for the sake of others’ gain, not ours.” —Shoshana Zuboff, The Age of Surveillance Capitalism.

Another concern of mine is that articles claiming privacy must die for cool technology to flourish is that the articles are not written by people who understand the underlying technology. The danger of continually citing the “expert opinions” of people running, or working for, big tech businesses, is that you’ll likely amplify their hype rather than report facts. The additional danger of garnering expertise from privileged people unfamiliar with the plights of marginalised communities, is that they are ill-equipped to understand the real impact that [profiling](https://www.nytimes.com/interactive/2018/12/10/business/location-data-privacy-apps.html), [algorithmic decision-making](https://www.vox.com/future-perfect/2019/3/5/18251924/self-driving-car-racial-bias-study-autonomous-vehicle-dark-skin) and [targeted propaganda](https://privacyinternational.org/press-release/2032/privacy-international-asks-major-uk-political-parties-commit-not-using-legal) can have on people’s lives.

Technology that gives us insight on our own behaviour is feasible without invading our privacy. Technology that makes our homes intelligent is feasible without invading our privacy. Technology that connects us to people across the world is feasible without invading our privacy. We can still have the shiny things without them having to spy on us. We could even have targeted ads that do not invade our privacy (whether we actually want this is a topic for another day…)

Much of the technology we use today could utilise our personal data without our data leaving our devices. We can communicate with each other without a corporation having access to our private messages. [Projects like this have existed](https://www.kickstarter.com/projects/edisonn/project-lima-a-one-way-internet-highway-by-0pii), and [more exist](https://cabal-club.github.io), but they are not mainstream. 

In part, they are not mainstream because the architecture is not developed to the extent of cloud-based surveillance systems. The vast majority of web architecture, libraries and developer tools are designed for cloud-based surveillance systems. They may feature some options for self-hosting, or encryption of particular elements, but they are still entangled with particular cloud services or servers. It is incredibly time-consuming to [utilise existing architecture but adapt it to respect people’s privacy](https://source.ind.ie/hypha/tools/acme-tls/activity). And many of the people working to build privacy-respecting technology have to work on these projects unpaid and in their free time. This worries me because it near-guarantees the only people working on alternatives to surveillance-based technologies are those who have free time, or those who can afford to work unpaid. Those people are invariably privileged, and not from marginalised communities. Which means there are greater chances of building new technologies that can cause harm in different ways, like [amplifying hate speech](https://alistapart.com/article/canary-in-a-coal-mine-how-tech-provides-platforms-for-hate).

The primary reason privacy-respecting innovative technology is not mainstream is because it is not funded. We do not have the economic models to support this technology because mainstream technology is mostly funded by venture capital. Venture capital’s desire for fast growth and “exits” through sale to bigger corporations or becoming a publicly-traded entity, further feeds the surveillance economy.

Privacy-respecting innovative technology is not infeasible, but we need economic models to support it. There is hope, we just need to stoke its fires.
